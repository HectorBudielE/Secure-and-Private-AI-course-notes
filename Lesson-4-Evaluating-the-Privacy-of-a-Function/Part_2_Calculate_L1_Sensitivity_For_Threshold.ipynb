{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 2 - Calculate L1 Sensitivity For Threshold.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb0E-roM6WqL",
        "colab_type": "text"
      },
      "source": [
        "## Lesson: Toy Differential Privacy - Simple Database Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru07sg6S6WqN",
        "colab_type": "text"
      },
      "source": [
        "In this section we're going to play around with Differential Privacy in the context of a database query. The database is going to be a VERY simple database with only one boolean column. Each row corresponds to a person. Each value corresponds to whether or not that person has a certain private attribute (such as whether they have a certain disease, or whether they are above/below a certain age). We are then going to learn how to know whether a database query over such a small database is differentially private or not - and more importantly - what techniques are at our disposal to ensure various levels of privacy\n",
        "\n",
        "\n",
        "### First We Create a Simple Database\n",
        "\n",
        "Step one is to create our database - we're going to do this by initializing a random list of 1s and 0s (which are the entries in our database). Note - the number of entries directly corresponds to the number of people in our database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkhhGZQQ6WqP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c44de72e-3e63-473e-e56b-565b7758fb67"
      },
      "source": [
        "import torch\n",
        "\n",
        "# the number of entries in our database\n",
        "num_entries = 5000\n",
        "\n",
        "db = torch.rand(num_entries) > 0.5\n",
        "db"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1,  ..., 1, 0, 1], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8fcStBH6WqW",
        "colab_type": "text"
      },
      "source": [
        "## Project: Generate Parallel Databases\n",
        "\n",
        "Key to the definition of differenital privacy is the ability to ask the question \"When querying a database, if I removed someone from the database, would the output of the query be any different?\". Thus, in order to check this, we must construct what we term \"parallel databases\" which are simply databases with one entry removed. \n",
        "\n",
        "In this first project, I want you to create a list of every parallel database to the one currently contained in the \"db\" variable. Then, I want you to create a function which both:\n",
        "\n",
        "- creates the initial database (db)\n",
        "- creates all parallel databases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_iTBLbz6WqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_parallel_db(db, remove_index):\n",
        "  \n",
        "  return torch.cat((db[0:remove_index],\n",
        "                    db[remove_index+1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "324jtHiT6Wqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_parallel_dbs(db):\n",
        "  \n",
        "  parallel_dbs = list()\n",
        "  \n",
        "  for i in range(len(db)):\n",
        "    pdb = get_parallel_db(db, i)\n",
        "    parallel_dbs.append(pdb)\n",
        "    \n",
        "  return parallel_dbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjaJCZF16Wqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_db_and_parallels(num_entries):\n",
        "  \n",
        "  db = torch.rand(num_entries) > 0.5\n",
        "  pdbs = get_parallel_dbs(db)\n",
        "  \n",
        "  return db, pdbs "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbzZzgWd6Wqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e195565e-0632-410e-94d5-ba3bb58df32b"
      },
      "source": [
        "db, pdbs = create_db_and_parallels(6)\n",
        "db"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 1, 1, 0], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVUteCUh6Wqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "714bc776-d11d-46ff-de59-e103add1a3eb"
      },
      "source": [
        "pdbs"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 0, 1, 1, 0], dtype=torch.uint8),\n",
              " tensor([0, 0, 1, 1, 0], dtype=torch.uint8),\n",
              " tensor([0, 0, 1, 1, 0], dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 1, 0], dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 1, 0], dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 1, 1], dtype=torch.uint8)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYo5Bd296Wqn",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Towards Evaluating The Differential Privacy of a Function\n",
        "\n",
        "Intuitively, we want to be able to query our database and evaluate whether or not the result of the query is leaking \"private\" information. As mentioned previously, this is about evaluating whether the output of a query changes when we remove someone from the database. Specifically, we want to evaluate the *maximum* amount the query changes when someone is removed (maximum over all possible people who could be removed). So, in order to evaluate how much privacy is leaked, we're going to iterate over each person in the database and measure the difference in the output of the query relative to when we query the entire database. \n",
        "\n",
        "Just for the sake of argument, let's make our first \"database query\" a simple sum. Aka, we're going to count the number of 1s in the database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXfInHBI6Wqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db, pdbs = create_db_and_parallels(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37iPJe1b6Wqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db):\n",
        "    return db.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k9Zgl4E6Wqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_db_result = query(db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs171Ujn6Wqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sensitivity = 0\n",
        "for pdb in pdbs:\n",
        "    pdb_result = query(pdb)\n",
        "    \n",
        "    db_distance = torch.abs(pdb_result - full_db_result)\n",
        "    \n",
        "    if(db_distance > sensitivity):\n",
        "        sensitivity = db_distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw0TnlX66Wq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8d13b80-ffca-4bad-c9fa-2117f74d5a47"
      },
      "source": [
        "sensitivity"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TuSSF5w6Wq7",
        "colab_type": "text"
      },
      "source": [
        "# Project - Evaluating the Privacy of a Function\n",
        "\n",
        "In the last section, we measured the difference between each parallel db's query result and the query result for the entire database and then calculated the max value (which was 1). This value is called \"sensitivity\", and it corresponds to the function we chose for the query. Namely, the \"sum\" query will always have a sensitivity of exactly 1. However, we can also calculate sensitivity for other functions as well.\n",
        "\n",
        "Let's try to calculate sensitivity for the \"mean\" function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSYZar2N6Wq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sensitivity(query, n_entries=1000):\n",
        "\n",
        "    db, pdbs = create_db_and_parallels(n_entries)\n",
        "    \n",
        "    full_db_result = query(db)\n",
        "    \n",
        "    max_distance = 0\n",
        "    for pdb in pdbs:\n",
        "        pdb_result = query(pdb)\n",
        "    \n",
        "        db_distance = torch.abs(pdb_result - full_db_result)\n",
        "    \n",
        "        if(db_distance > max_distance):\n",
        "            max_distance = db_distance\n",
        "    \n",
        "    return max_distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs8KAWS06Wq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db):\n",
        "    return db.float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLQ8S8Jg6WrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35692858-2132-4aa6-e544-e05021c85cbf"
      },
      "source": [
        "sensitivity(query)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0005)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_LFXpfD6WrW",
        "colab_type": "text"
      },
      "source": [
        "Wow! That sensitivity is WAY lower. Note the intuition here. \"Sensitivity\" is measuring how sensitive the output of the query is to a person being removed from the database. For a simple sum, this is always 1, but for the mean, removing a person is going to change the result of the query by rougly 1 divided by the size of the database (which is much smaller). Thus, \"mean\" is a VASTLY less \"sensitive\" function (query) than SUM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc3nYg06WrX",
        "colab_type": "text"
      },
      "source": [
        "# Project: Calculate L1 Sensitivity For Threshold\n",
        "\n",
        "In this first project, I want you to calculate the sensitivty for the \"threshold\" function. \n",
        "\n",
        "- First compute the sum over the database (i.e. sum(db)) and return whether that sum is greater than a certain threshold.\n",
        "- Then, I want you to create databases of size 10 and threshold of 5 and calculate the sensitivity of the function. \n",
        "- Finally, re-initialize the database 10 times and calculate the sensitivity each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U592MKll6WrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db, threshold=5):\n",
        "    return (db.sum()>threshold).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irivClTy6Wrc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "06ba62ff-e5ce-4e9e-9bb6-51abd743be24"
      },
      "source": [
        "for i in range(10):\n",
        "    sens_f =  sensitivity(query, n_entries=10)\n",
        "    print(sens_f)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "tensor(1.)\n",
            "0\n",
            "tensor(1.)\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}